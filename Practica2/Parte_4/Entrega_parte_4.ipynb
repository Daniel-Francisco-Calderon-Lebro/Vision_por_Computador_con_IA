{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Comparativo de Modelos de Clasificación\n",
    "\n",
    "Este informe presenta un análisis exhaustivo de varios modelos de clasificación entrenados sobre un conjunto de datos. Los modelos evaluados incluyen **Árbol de Decisión**, **Regresión Logística**, **Bosques Aleatorios**, **Naive Bayes**, **Máquinas de Soporte Vectorial (SVM)**, **K-Means**, y una **Red Neuronal MLP**. Se han empleado las métricas estándar para la evaluación del rendimiento: **Precisión**, **Recall (Sensibilidad)**, **F1-score**, **Accuracy** y **Especificidad**.\n",
    "\n",
    "## Resultados de los Modelos\n",
    "\n",
    "### 1. Árbol de Decisión\n",
    "- **Precisión**: 0.94\n",
    "- **Recall (Sensibilidad)**: 0.94\n",
    "- **F1-score**: 0.94\n",
    "- **Accuracy**: 0.93\n",
    "- **Especificidad**: 0.96\n",
    "\n",
    "### 2. Regresión Logística\n",
    "- **Precisión**: 0.94\n",
    "- **Recall (Sensibilidad)**: 0.94\n",
    "- **F1-score**: 0.94\n",
    "- **Accuracy**: 0.93\n",
    "- **Especificidad**: 0.96\n",
    "\n",
    "### 3. Bosques Aleatorios\n",
    "- **Precisión**: 0.96\n",
    "- **Recall (Sensibilidad)**: 0.96\n",
    "- **F1-score**: 0.96\n",
    "- **Accuracy**: 0.96\n",
    "- **Especificidad**: 0.98\n",
    "\n",
    "### 4. Naive Bayes\n",
    "- **Precisión**: 0.96\n",
    "- **Recall (Sensibilidad)**: 0.96\n",
    "- **F1-score**: 0.96\n",
    "- **Accuracy**: 0.96\n",
    "- **Especificidad**: 0.98\n",
    "\n",
    "### 5. Máquinas de Soporte Vectorial (SVM)\n",
    "- **Precisión**: 0.98\n",
    "- **Recall (Sensibilidad)**: 0.98\n",
    "- **F1-score**: 0.98\n",
    "- **Accuracy**: 0.98\n",
    "- **Especificidad**: 0.99\n",
    "\n",
    "### 6. K-Means\n",
    "- **Precisión**: 0.91\n",
    "- **Recall (Sensibilidad)**: 0.89\n",
    "- **F1-score**: 0.89\n",
    "- **Accuracy**: 0.89\n",
    "- **Especificidad**: 0.95\n",
    "\n",
    "### 7. Red Neuronal MLP\n",
    "- **Precisión**: 0.98\n",
    "- **Recall (Sensibilidad)**: 0.98\n",
    "- **F1-score**: 0.98\n",
    "- **Accuracy**: 0.98\n",
    "- **Especificidad**: 0.99\n",
    "\n",
    "## Comparación de Resultados\n",
    "\n",
    "### Precisión\n",
    "- **SVM** y **MLP** son los modelos que obtienen la mayor precisión (0.98), superando a los demás modelos, especialmente a K-Means y Árbol de Decisión.\n",
    "- **Bosques Aleatorios** y **Naive Bayes** siguen de cerca con una precisión del 0.96.\n",
    "\n",
    "### Recall (Sensibilidad)\n",
    "- **SVM** y **MLP** lideran nuevamente con un recall de 0.98, lo que indica que son los mejores identificando correctamente las instancias positivas.\n",
    "- **K-Means** tiene el valor más bajo en este apartado con un 0.89.\n",
    "\n",
    "### F1-Score\n",
    "- **SVM** y **MLP** muestran un excelente balance entre precisión y recall con un F1-score de 0.98.\n",
    "- Modelos como **Bosques Aleatorios** y **Naive Bayes** también obtienen buenos resultados (0.96), mientras que **K-Means** y **Árbol de Decisión** son más modestos con valores cercanos al 0.89-0.94.\n",
    "\n",
    "### Accuracy\n",
    "- **SVM**, **MLP**, **Bosques Aleatorios** y **Naive Bayes** presentan la mayor exactitud, con valores cercanos al 0.98 y 0.96 respectivamente.\n",
    "- **Árbol de Decisión** y **Regresión Logística** tienen una exactitud ligeramente menor de 0.93, mientras que **K-Means** tiene un rendimiento más bajo en términos de exactitud con 0.89.\n",
    "\n",
    "### Especificidad\n",
    "- **SVM** y **MLP** son los más efectivos para evitar falsos positivos, con una especificidad de 0.99.\n",
    "- **Bosques Aleatorios** y **Naive Bayes** muestran también una alta especificidad (0.98), mientras que **Árbol de Decisión** y **Regresión Logística** están ligeramente por debajo, en torno a 0.96.\n",
    "\n",
    "## Optimización de Hiperparámetros\n",
    "\n",
    "El ajuste de los hiperparámetros es crucial para mejorar el rendimiento de los modelos. A continuación, se presentan algunas recomendaciones para la optimización de los modelos evaluados:\n",
    "\n",
    "- **Árbol de Decisión**: Modificar parámetros como `max_depth`, `min_samples_split` y `criterion` puede mejorar la precisión sin sobreajustar el modelo.\n",
    "- **Regresión Logística**: Variar el `C` para el control de regularización o usar técnicas como la validación cruzada puede mejorar los resultados.\n",
    "- **Bosques Aleatorios**: Incrementar el número de árboles (`n_estimators`) o ajustar la profundidad máxima puede conducir a mejoras en la estabilidad y rendimiento del modelo.\n",
    "- **SVM**: Ajustar el parámetro `C` y elegir diferentes kernels (`linear`, `rbf`, etc.) puede mejorar el rendimiento para diferentes conjuntos de datos.\n",
    "- **Red Neuronal MLP**: Cambiar la configuración de las capas ocultas o el algoritmo de optimización (`adam`, `sgd`) y ajustar la tasa de aprendizaje puede impactar significativamente los resultados.\n",
    "\n",
    "\n",
    "##### Impacto: Modificar estas configuraciones puede hacer que el modelo entrene más rápido o aprenda mejor, pero también puede aumentar la complejidad o el riesgo de sobreajuste. La clave está en ajustar estos hiperparámetros para optimizar el rendimiento del modelo\n",
    "\n",
    "## Validación de los Modelos\n",
    "\n",
    "Se utilizó la **matriz de confusión** para obtener métricas detalladas como precisión, recall y especificidad, evaluando tanto los verdaderos positivos como los falsos positivos y negativos.\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "1. **Máquinas de Soporte Vectorial (SVM)** y la **Red Neuronal MLP** ofrecen el mejor rendimiento general en términos de todas las métricas evaluadas. Estos modelos muestran un excelente balance entre precisión, recall y especificidad, haciéndolos ideales para problemas de clasificación complejos.\n",
    "   \n",
    "2. **Bosques Aleatorios** y **Naive Bayes** también son modelos muy robustos, obteniendo métricas competitivas, aunque ligeramente por debajo de SVM y MLP.\n",
    "\n",
    "3. **K-Means**, al ser un algoritmo no supervisado, presenta un rendimiento inferior, pero es destacable que haya alcanzado un valor de precisión y especificidad razonable para un modelo de clustering.\n",
    "\n",
    "4. **Árbol de Decisión** y **Regresión Logística** son modelos efectivos con un rendimiento sólido, pero menos competitivos que los modelos más complejos como SVM y MLP en este conjunto de datos.\n",
    "\n",
    "### Recomendaciones Finales\n",
    "\n",
    "Para futuros experimentos, se recomienda:\n",
    "\n",
    "- Explorar técnicas adicionales de ajuste de hiperparámetros y realizar validaciones cruzadas más detalladas para todos los modelos.\n",
    "- Considerar la utilización de técnicas de **ensamblaje** (e.g., stacking o boosting) para combinar los modelos y mejorar el rendimiento general.\n",
    "- Realizar un análisis de la importancia de las características (particularmente en Árboles de Decisión y Bosques Aleatorios) para entender mejor cuáles variables están impulsando las predicciones.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
